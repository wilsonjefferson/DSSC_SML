{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple RNN from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "- Creating your customized dataset\n",
    "- Implement a simple RNN module from scratch\n",
    "- NLLLoss vs CrossEntropyLoss\n",
    "- Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "torch.manual_seed(13)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils.data_helpers import EvenOddDataset\n",
    "\n",
    "size = 200\n",
    "start = 0\n",
    "trainset = EvenOddDataset(size, start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        combined = torch.cat((x, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.logsoftmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden_state(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "    def predict(self, tensor):\n",
    "        with torch.no_grad():\n",
    "            hidden = self.init_hidden_state()\n",
    "\n",
    "            for i in range(tensor.size()[0]):\n",
    "                output, hidden = self.forward(tensor[i], hidden)\n",
    "            pred = output.argmax(dim=1).item()\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "print_period = epochs // 20\n",
    "\n",
    "input_size_for_single_step = 1\n",
    "n_hidden = 200\n",
    "fc_size = 20\n",
    "n_classes = 2\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "\n",
    "rnn = RNN(input_size_for_single_step, n_hidden, n_classes)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=learning_rate, momentum=momentum)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, epochs // 5, gamma=0.7)\n",
    "\n",
    "print(\"Learning rate: {}\".format(optimizer.param_groups[0]['lr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 5% (0m 1s) 0.4508 Guess: 64 / 1 ✓\n",
      "Learning rate: 0.001\n",
      "\n",
      "1000 10% (0m 1s) 0.2229 Guess: 196 / 1 ✓\n",
      "Learning rate: 0.001\n",
      "\n",
      "1500 15% (0m 2s) 0.1458 Guess: 187 / 0 ✓\n",
      "Learning rate: 0.001\n",
      "\n",
      "2000 20% (0m 3s) 0.1324 Guess: 199 / 0 ✓\n",
      "Learning rate: 0.001\n",
      "\n",
      "2500 25% (0m 4s) 0.1269 Guess: 79 / 0 ✓\n",
      "Learning rate: 0.0007\n",
      "\n",
      "3000 30% (0m 5s) 0.0841 Guess: 68 / 1 ✓\n",
      "Learning rate: 0.0007\n",
      "\n",
      "3500 35% (0m 5s) 0.0853 Guess: 164 / 1 ✓\n",
      "Learning rate: 0.0007\n",
      "\n",
      "4000 40% (0m 6s) 0.0666 Guess: 75 / 0 ✓\n",
      "Learning rate: 0.0007\n",
      "\n",
      "4500 45% (0m 6s) 0.0577 Guess: 82 / 1 ✓\n",
      "Learning rate: 0.00049\n",
      "\n",
      "5000 50% (0m 7s) 0.0499 Guess: 193 / 0 ✓\n",
      "Learning rate: 0.00049\n",
      "\n",
      "5500 55% (0m 8s) 0.0463 Guess: 102 / 1 ✓\n",
      "Learning rate: 0.00049\n",
      "\n",
      "6000 60% (0m 8s) 0.0456 Guess: 105 / 0 ✓\n",
      "Learning rate: 0.00049\n",
      "\n",
      "6500 65% (0m 9s) 0.0472 Guess: 161 / 0 ✓\n",
      "Learning rate: 0.000343\n",
      "\n",
      "7000 70% (0m 10s) 0.0536 Guess: 176 / 1 ✓\n",
      "Learning rate: 0.000343\n",
      "\n",
      "7500 75% (0m 10s) 0.0455 Guess: 180 / 1 ✓\n",
      "Learning rate: 0.000343\n",
      "\n",
      "8000 80% (0m 11s) 0.0487 Guess: 130 / 1 ✓\n",
      "Learning rate: 0.000343\n",
      "\n",
      "8500 85% (0m 12s) 0.0390 Guess: 118 / 1 ✓\n",
      "Learning rate: 0.00024009999999999998\n",
      "\n",
      "9000 90% (0m 13s) 0.0479 Guess: 151 / 0 ✓\n",
      "Learning rate: 0.00024009999999999998\n",
      "\n",
      "9500 95% (0m 13s) 0.0500 Guess: 32 / 1 ✓\n",
      "Learning rate: 0.00024009999999999998\n",
      "\n",
      "10000 100% (0m 14s) 0.0442 Guess: 28 / 1 ✓\n",
      "Learning rate: 0.00024009999999999998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.data_helpers import num_from_tensor\n",
    "from utils.misc import time_since\n",
    "\n",
    "\n",
    "def train_step(tens, target, rnn, criterion, optimizer):\n",
    "    hidden = rnn.init_hidden_state()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i in range(tens.size()[0]):\n",
    "        output, hidden = rnn(tens[i], hidden)\n",
    "\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for e in range(1, epochs + 1):\n",
    "    tens, target = trainset.sample()\n",
    "    output, loss = train_step(tens, target, rnn, criterion, optimizer)\n",
    "\n",
    "    if e % print_period == 0:\n",
    "        guess = output.argmax(dim=1).item()\n",
    "        correct = '✓' if guess == target else '✗ True class: %s' % target.item()\n",
    "        print('%d %d%% (%s) %.4f Guess: %s / %s %s' %\n",
    "              (e, e / epochs * 100, time_since(start), loss, num_from_tensor(tens), guess, correct))\n",
    "\n",
    "        print(\"Learning rate: {}\\n\".format(optimizer.param_groups[0]['lr']))\n",
    "    lr_scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Resources\n",
    "[Adjusting the learning rate](https://pytorch.org/docs/master/optim.html#how-to-adjust-learning-rate)\n",
    "\n",
    "[Writing custom datasets](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)\n",
    "\n",
    "[Nice animated visualizations](https://towardsdatascience.com/animated-rnn-lstm-and-gru-ef124d06cf45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
