{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network on CIFAR10\n",
    "**Outline**\n",
    "- Convolutional layers\n",
    "- Pooling layers\n",
    "- Dropout\n",
    "- [model.train()](https://pytorch.org/docs/stable/nn.html?highlight=train#torch.nn.Module.train) and [model.eval()](https://pytorch.org/docs/stable/nn.html?highlight=eval#torch.nn.Module.eval)\n",
    "- Residual block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution's properties\n",
    "![convolution](./images/conv.png)\n",
    "Some properties which make this transformation such a popular choice for deep learning algorithms:\n",
    "\n",
    "1. **Sparse interactions**: traditionally, each output interacts with each input, since a matrix multiplication is performed. In CNN, kernels are definitely smaller than the input, since it is made the assumption that the relevant interactions are local. This allows to store fewer parameters, reducing the memory requirements of the model and the number of operations for the output to be computed.\n",
    "\n",
    "![sparsity](./images/sparsity.png)\n",
    "\n",
    "2. **Parameters sharing**: for a densely connected layer, each weight defines a single interaction between an element of the input and an element of the output, and it is used exactly once during the computation of the output layer. CNNs, on the other hand, have \\textit{tied weights}, that means that a relatively small set of weights is shared by a larger set of inputs to produce the next layer's elements.\n",
    "\n",
    "3. **Equivariant representations**: a function $f$ is equivariant to a function $g$ if $f(g(x)) = g(f(x))$. Let $g$ be a function that shifts the input; therefore, the convolution operation is equivariant to any input's shift. In other words, let's suppose that a specific representation is associated by the convolution to a particular event in the time series. If we shift the same event $N$ time steps later, the output for the shifted sequence will show the exact same representation $N$ steps later (assuming there is no a resizing process within the transformation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "\n",
    "![max pooling](./images/max_pooling.png)\n",
    "A pooling function is a transformation that summarizes the local properties for a certain location within the input. \n",
    "\n",
    "A common form of pooling is called **max pooling**, which reports the maximum value within a window. This introduces invariance to small translations, shrinking the information and reducing the number of parameters needed for the following layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "![dropout](./images/dropout.png)\n",
    "\n",
    "For dropping out a neuron we mean removing it from the network for that specific iteration. In particular, it is implemented by assigning to each neuron of a layer a probability $p$ for its output to be multiplied by zero just for that specific training iteration. The probability $p$ is usually set to a number between $0.25$ and $0.5$ during the training process. It must be set to $0.0$ during the validation and the test iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils.misc import get_params_num, get_accuracy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from IPython import display\n",
    "\n",
    "torch.manual_seed(2)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "CIFAR images shape: (3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# import CIFAR10\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "print(\"CIFAR images shape: {}\".format(tuple(trainset[0][0].shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters: 83978\n",
      "CNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (out): Linear(in_features=4608, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.input_dim = 3 * 32 * 32\n",
    "        self.n_classes = 10\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 128, kernel_size=3)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.out = nn.Linear(128 * 6 * 6, self.n_classes)\n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.maxpool(x) # F.max_pool2d(x, kernel_size=2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool(x) # F.max_pool2d(x, kernel_size=2)\n",
    "        x = x.view(-1, 128 * 6 * 6)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "net = CNN()\n",
    "net.to(device)\n",
    "print(\"# of parameters: {}\".format(get_params_num(net)))\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 19, [BATCH]: 750/782, [LOSS]: 0.6600993871688843\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "epochs = 20\n",
    "\n",
    "n_batches = len(trainloader)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "net.train() \n",
    "for e in range(epochs):\n",
    "    for i, data in enumerate(trainloader):\n",
    "        batch = data[0].to(device)\n",
    "        labels = data[1].to(device)      \n",
    "        outputs = net(batch)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 50 == 0:\n",
    "            print(\"[EPOCH]: {}, [BATCH]: {}/{}, [LOSS]: {}\".format(e, i, n_batches, loss.item()))\n",
    "            display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.73458\n",
      "Test accuracy: 0.6867\n"
     ]
    }
   ],
   "source": [
    "acc_train = get_accuracy(trainloader, net, device=device)\n",
    "acc_test = get_accuracy(testloader, net, device=device)\n",
    "print(\"Train accuracy: {}\\nTest accuracy: {}\".format(acc_train, acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrambled CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scramble_image(tensor, indices):\n",
    "    tensor = tensor.view(-1)[indices].view(3, 32, 32)\n",
    "    return tensor\n",
    "\n",
    "indices = np.arange(3*32*32)\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CIFAR10\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "     transforms.Lambda(lambda tens: scramble_image(tens, indices))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 19, [BATCH]: 750/782, [LOSS]: 1.1913037300109863\n"
     ]
    }
   ],
   "source": [
    "net = CNN()\n",
    "net.to(device)\n",
    "\n",
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "epochs = 20\n",
    "\n",
    "n_batches = len(trainloader)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "net.train() \n",
    "for e in range(epochs):\n",
    "    for i, data in enumerate(trainloader):\n",
    "        batch = data[0].to(device)\n",
    "        labels = data[1].to(device)      \n",
    "        outputs = net(batch)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 50 == 0:\n",
    "            print(\"[EPOCH]: {}, [BATCH]: {}/{}, [LOSS]: {}\".format(e, i, n_batches, loss.item()))\n",
    "            display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.59886\n",
      "Test accuracy: 0.5008\n"
     ]
    }
   ],
   "source": [
    "acc_train = get_accuracy(trainloader, net, device=device)\n",
    "acc_test = get_accuracy(testloader, net, device=device)\n",
    "print(\"Train accuracy: {}\\nTest accuracy: {}\".format(acc_train, acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making our CNN a bit fancier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CIFAR10\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters: 247382\n",
      "CNN(\n",
      "  (network): Sequential(\n",
      "    (0): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ResidualBlock(\n",
      "      (bottleneck): Bottleneck(\n",
      "        (bottleneck): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (expansion): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "    )\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "    (5): GlobalAveragePooling()\n",
      "    (6): Linear(in_features=256, out_features=100, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "    (8): Dropout(p=0.25, inplace=False)\n",
      "    (9): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_factor):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.bottleneck = nn.Conv2d(in_channels,in_channels // reduction_factor, kernel_size=1)\n",
    "        self.conv = nn.Conv2d(in_channels // reduction_factor, in_channels // reduction_factor, \n",
    "                              padding=1, kernel_size=3)\n",
    "        self.expansion = nn.Conv2d(in_channels // reduction_factor, in_channels, kernel_size=1)\n",
    "        self.act = nn.LeakyReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.act(self.bottleneck(x))\n",
    "        x = self.act(self.conv(x))\n",
    "        x = self.expansion(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_factor):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.bottleneck = Bottleneck(in_channels, reduction_factor)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.bottleneck(x)\n",
    "    \n",
    "    \n",
    "class GlobalAveragePooling(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.mean(x.view(x.size(0), x.size(1), -1), dim=2)\n",
    "    \n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        C = 256\n",
    "        n_classes = 10\n",
    "        \n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3, out_channels=C, kernel_size=3),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                ResidualBlock(C, 2),\n",
    "                nn.LeakyReLU(),\n",
    "                GlobalAveragePooling(),\n",
    "                nn.Linear(C, 100),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout(p=0.25),\n",
    "                nn.Linear(100, n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        return self.network(x)\n",
    "        \n",
    "        \n",
    "net = CNN()\n",
    "net.to(device)\n",
    "print(\"# of parameters: {}\".format(get_params_num(net)))\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 19, [BATCH]: 750/782, [LOSS]: 0.3826696276664734\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "epochs = 20\n",
    "\n",
    "n_batches = len(trainloader)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "net.train() \n",
    "for e in range(epochs):\n",
    "    for i, data in enumerate(trainloader):\n",
    "        batch = data[0].to(device)\n",
    "        labels = data[1].to(device)      \n",
    "        outputs = net(batch)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 50 == 0:\n",
    "            print(\"[EPOCH]: {}, [BATCH]: {}/{}, [LOSS]: {}\".format(e, i, n_batches, loss.item()))\n",
    "            display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.83066\n",
      "Test accuracy: 0.7623\n"
     ]
    }
   ],
   "source": [
    "acc_train = get_accuracy(trainloader, net, device=device)\n",
    "acc_test = get_accuracy(testloader, net, device=device)\n",
    "print(\"Train accuracy: {}\\nTest accuracy: {}\".format(acc_train, acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'saved_models/fancy_net_CIFAR10.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = CNN()\n",
    "# net.load_state_dict(torch.load('saved_models/fancy_net_CIFAR10.pt'))\n",
    "# net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Resources:\n",
    "[Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)\n",
    "\n",
    "[Dropout](http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n",
    "\n",
    "[A nice explanation in three parts](https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/)\n",
    "\n",
    "[Saving and loading models](https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}