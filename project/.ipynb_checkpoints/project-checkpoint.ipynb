{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/eferos93/sml_project/blob/master/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zX8mwS7rIp7R"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import load_files\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "L0XNZEm-P0sy",
    "outputId": "4d2e0acb-5b44-4e98-9b96-f349a03e2774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open drive/My Drive/5857_1166105_bundle_archive, drive/My Drive/5857_1166105_bundle_archive.zip or drive/My Drive/5857_1166105_bundle_archive.ZIP.\r\n"
     ]
    }
   ],
   "source": [
    "!unzip drive/My\\ Drive/5857_1166105_bundle_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FqowUObxIoTQ",
    "outputId": "2e4ce2b8-2a36-4d36-a17e-eb0417ae120c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PSLAUmvLettn",
    "outputId": "b5c2682e-0e44-4a67-a292-ab6a20946675"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in Training file: 67692\n"
     ]
    }
   ],
   "source": [
    "path = \"data/fruits/fruits-360/\"\n",
    "files_training = glob(os.path.join(path,'Training', '*/*.jpg'))\n",
    "num_images = len(files_training)\n",
    "print('Number of images in Training file:', num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VoFm6RmsY2qc",
    "outputId": "b46ef783-1f3d-479d-c46b-0e11d071dc85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/fruits/fruits-360/Training/*/*.jpg'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "glob(os.path.join(path,'Training', '*/*.jpg'))\n",
    "os.path.join(path,'Training', '*/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "t2XzGpyhZR7S",
    "outputId": "0cab7928-6e4f-46f5-89e1-d979f14a196a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class             Count:\n",
      "------------------------\n",
      "Apple Braeburn       492\n",
      "Apple Crimson Snow   444\n",
      "Apple Golden 1       480\n",
      "Apple Golden 2       492\n",
      "Apple Golden 3       481\n",
      "Apple Granny Smith   492\n",
      "Apple Pink Lady      456\n",
      "Apple Red 1          492\n",
      "Apple Red 2          492\n",
      "Apple Red 3          429\n",
      "Apple Red Delicious  490\n",
      "Apple Red Yellow 1   492\n",
      "Apple Red Yellow 2   672\n",
      "Apricot              492\n",
      "Avocado              427\n",
      "Avocado ripe         491\n",
      "Banana               490\n",
      "Banana Lady Finger   450\n",
      "Beetroot             450\n",
      "Blueberry            462\n",
      "Cactus fruit         490\n",
      "Cantaloupe 1         492\n",
      "Cantaloupe 2         492\n",
      "Carambula            490\n",
      "Cauliflower          702\n",
      "Cherry 1             492\n",
      "Cherry 2             738\n",
      "Cherry Rainier       738\n",
      "Cherry Wax Black     492\n",
      "Cherry Wax Red       492\n",
      "Cherry Wax Yellow    492\n",
      "Chestnut             450\n",
      "Clementine           490\n",
      "Cocos                490\n",
      "Corn                 450\n",
      "Corn Husk            462\n",
      "Cucumber Ripe 2      468\n",
      "Dates                490\n",
      "Eggplant             468\n",
      "Fig                  702\n",
      "Ginger Root          297\n",
      "Granadilla           490\n",
      "Grape Blue           984\n",
      "Grape Pink           492\n",
      "Grape White          490\n",
      "Grape White 2        490\n",
      "Grape White 3        492\n",
      "Grape White 4        471\n",
      "Grapefruit Pink      490\n",
      "Grapefruit White     492\n",
      "Guava                490\n",
      "Hazelnut             464\n",
      "Huckleberry          490\n",
      "Kaki                 490\n",
      "Kiwi                 466\n",
      "Kumquats             490\n",
      "Lemon                492\n",
      "Lemon Meyer          490\n",
      "Limes                490\n",
      "Lychee               490\n",
      "Mandarine            490\n",
      "Mango                490\n",
      "Mango Red            426\n",
      "Mangostan            300\n",
      "Maracuja             490\n",
      "Melon Piel de Sapo   738\n",
      "Mulberry             492\n",
      "Nectarine            492\n",
      "Nectarine Flat       480\n",
      "Nut Forest           654\n",
      "Nut Pecan            534\n",
      "Onion Red            450\n",
      "Onion Red Peeled     445\n",
      "Onion White          438\n",
      "Papaya               492\n",
      "Passion Fruit        490\n",
      "Peach                492\n",
      "Peach 2              738\n",
      "Peach Flat           492\n",
      "Pear                 492\n",
      "Pear 2               696\n",
      "Pear Abate           490\n",
      "Pear Forelle         702\n",
      "Pear Kaiser          300\n",
      "Pear Monster         490\n",
      "Pear Red             666\n",
      "Pear Stone           711\n",
      "Pear Williams        490\n",
      "Pepino               490\n",
      "Pepper Green         444\n",
      "Pepper Orange        702\n",
      "Pepper Red           666\n",
      "Pepper Yellow        666\n",
      "Banana Red           490\n",
      "Cucumber Ripe        392\n",
      "Kohlrabi             471\n",
      "Orange               479\n",
      "Physalis             492\n",
      "Physalis with Husk   492\n",
      "Pineapple            490\n",
      "Pineapple Mini       493\n",
      "Pitahaya Red         490\n",
      "Plum                 447\n",
      "Plum 2               420\n",
      "Plum 3               900\n",
      "Pomegranate          492\n",
      "Pomelo Sweetie       450\n",
      "Potato Red           450\n",
      "Potato Red Washed    453\n",
      "Potato Sweet         450\n",
      "Potato White         450\n",
      "Quince               490\n",
      "Rambutan             492\n",
      "Raspberry            490\n",
      "Redcurrant           492\n",
      "Salak                490\n",
      "Strawberry           492\n",
      "Strawberry Wedge     738\n",
      "Tamarillo            490\n",
      "Tangelo              490\n",
      "Tomato 1             738\n",
      "Tomato 2             672\n",
      "Tomato 3             738\n",
      "Tomato 4             479\n",
      "Tomato Cherry Red    492\n",
      "Tomato Heart         684\n",
      "Tomato Maroon        367\n",
      "Tomato not Ripened   474\n",
      "Tomato Yellow        459\n",
      "Walnut               735\n",
      "Watermelon           475\n",
      "\n",
      "Minumum imgages per category: 297 Category: Watermelon\n",
      "Average number of Images per Category: 517\n",
      "Total number of classes: 131\n"
     ]
    }
   ],
   "source": [
    "min_images = 1000\n",
    "im_cnt = []\n",
    "class_names = []\n",
    "print('{:18s}'.format('class'), end='')\n",
    "print('Count:')\n",
    "print('-' * 24)\n",
    "for folder in os.listdir(os.path.join(path, 'Training')):\n",
    "    folder_num = len(os.listdir(os.path.join(path,'Training',folder)))\n",
    "    im_cnt.append(folder_num)\n",
    "    class_names.append(folder)\n",
    "    print('{:20s}'.format(folder), end=' ')\n",
    "    print(folder_num)\n",
    "    if (folder_num < min_images):\n",
    "        min_images = folder_num\n",
    "        folder_name = folder\n",
    "        \n",
    "num_classes = len(class_names)\n",
    "print(\"\\nMinumum imgages per category:\", min_images, 'Category:', folder)    \n",
    "print('Average number of Images per Category: {:.0f}'.format(np.array(im_cnt).mean()))\n",
    "print('Total number of classes: {}'.format(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bQ_dZtRZgDW"
   },
   "outputs": [],
   "source": [
    "tensor_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "all_data = ImageFolder(os.path.join(path, 'Training'), tensor_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9Kd5shSZizl"
   },
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(all_data, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "i1PRrOcrZn5h",
    "outputId": "141d89c1-0863-4956-fb5a-a2964cae3390",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0b25812e6b67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpop_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mnumpy_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \"\"\"\n\u001b[1;32m    136\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2885\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2887\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2889\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pop_mean = []\n",
    "pop_std = []\n",
    "\n",
    "for i, data in enumerate(data_loader, 0):\n",
    "    numpy_image = data[0].numpy()\n",
    "    \n",
    "    batch_mean = np.mean(numpy_image, axis=(0,2,3))\n",
    "    batch_std = np.std(numpy_image, axis=(0,2,3))\n",
    "    \n",
    "    pop_mean.append(batch_mean)\n",
    "    pop_std.append(batch_std)\n",
    "\n",
    "pop_mean = np.array(pop_mean).mean(axis=0)\n",
    "pop_std = np.array(pop_std).mean(axis=0)\n",
    "\n",
    "print(pop_mean)\n",
    "print(pop_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qhzdLDxDaUCi"
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "shuffle = np.random.permutation(num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "BsT9Qe8baXLK",
    "outputId": "b2de2687-2bf9-4a93-a170-395d730d2529"
   },
   "outputs": [],
   "source": [
    "split_val = int(num_images * 0.2)\n",
    "print('Total number of images:', num_images)\n",
    "print('Number of valid images after split:',len(shuffle[:split_val]))\n",
    "print('Number of train images after split:',len(shuffle[split_val:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1oXyBqXwcWWJ"
   },
   "outputs": [],
   "source": [
    "class FruitTrainDataset(Dataset):\n",
    "    def __init__(self, files, shuffle, split_val, class_names, transform=transforms.ToTensor()):\n",
    "        self.shuffle = shuffle\n",
    "        self.class_names = class_names\n",
    "        self.split_val = split_val\n",
    "        self.data = np.array([files[i] for i in shuffle[split_val:]])\n",
    "        self.transform=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.data[idx])\n",
    "        name = self.data[idx].split('/')[-2]\n",
    "        y = self.class_names.index(name)\n",
    "        img = self.transform(img)\n",
    "            \n",
    "        return img, y\n",
    "\n",
    "class FruitValidDataset(Dataset):\n",
    "    def __init__(self, files, shuffle, split_val, class_names, transform=transforms.ToTensor()):\n",
    "        self.shuffle = shuffle\n",
    "        self.class_names = class_names\n",
    "        self.split_val = split_val\n",
    "        self.data = np.array([files[i] for i in shuffle[:split_val]])\n",
    "        self.transform=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.data[idx])\n",
    "        name = self.data[idx].split('/')[-2]\n",
    "        y = self.class_names.index(name)\n",
    "        img = self.transform(img)\n",
    "            \n",
    "        return img, y\n",
    "    \n",
    "class FruitTestDataset(Dataset):\n",
    "    def __init__(self, path, class_names, transform=transforms.ToTensor()):\n",
    "        self.class_names = class_names\n",
    "        self.data = np.array(glob(os.path.join(path, '*/*.jpg')))\n",
    "        self.transform=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.data[idx])\n",
    "        name = self.data[idx].split('/')[-2]\n",
    "        y = self.class_names.index(name)\n",
    "        img = self.transform(img)\n",
    "            \n",
    "        return img, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f9iBYr_ycXYk"
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(pop_mean, pop_std) # These were the mean and standard deviations that we calculated earlier.\n",
    "    ]),\n",
    "    'Test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(pop_mean, pop_std) # These were the mean and standard deviations that we calculated earlier.\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(pop_mean, pop_std) # These were the mean and standard deviations that we calculated earlier.\n",
    "    ])\n",
    "}\n",
    "\n",
    "train_dataset = FruitTrainDataset(files_training, shuffle, split_val, class_names, data_transforms['train'])\n",
    "valid_dataset = FruitValidDataset(files_training, shuffle, split_val, class_names, data_transforms['valid'])\n",
    "test_dataset = FruitTestDataset('/content/fruits-360/Test', class_names, transform=data_transforms['Test'])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cNlrIzLjcu84"
   },
   "outputs": [],
   "source": [
    "dataloaders = {'train': train_loader,\n",
    "              'valid': valid_loader,\n",
    "              'Test': test_loader}\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'valid': len(valid_dataset),\n",
    "    'Test': len(test_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EdD6hoELcz9m"
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = pop_std * inp + pop_mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "_pJwqU8Jc2Zh",
    "outputId": "066c3776-3420-4317-9346-722f766d9299"
   },
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(train_loader))\n",
    "out = make_grid(inputs)\n",
    "\n",
    "cats = ['' for x in range(len(classes))]\n",
    "for i in range(len(classes)):\n",
    "    cats[i] = class_names[classes[i].item()]\n",
    "    \n",
    "imshow(out)\n",
    "print(cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rlnXTcp0c6Rw"
   },
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "304788cedc904dec887ad1df4014925f",
      "48fe9858dba94bcf8ebda5b0980ab3d5",
      "c3657cb204de4850b6c3bde07cd355ed",
      "3ca860ee18a34b11844d9dcaed4c44cf",
      "2d6ade54451f4a2687da3bdc88e4a863",
      "b41d8b7d46404ddb92c246fd040ba9ff",
      "c951a746541e411abce3ef98edc0a273",
      "8bc11a88008f42c9a0b3e073b7bfcdd8"
     ]
    },
    "colab_type": "code",
    "id": "iaH1gKObc9qe",
    "outputId": "e29cd82a-95f8-4fc0-b635-a2eebc84be6f"
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.vgg11(num_classes)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "exp_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMtnCoBHgFqf"
   },
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, scheduler, num_epochs=30):\n",
    "    since = time.time() # allows us to keep track of how long it took\n",
    "    \n",
    "    best_acc = 0.0 # allows us to store the best_acc rate (for validation stage)\n",
    "    \n",
    "    # Loop through the data-set num_epochs times.\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 15)\n",
    "        \n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train() # This sets the model to training mode\n",
    "            else:\n",
    "                model.eval() # this sets the model to evaluation mode \n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # using the dataloaders to load data in batches\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                # putting the inputs and labels on cuda (gpu)\n",
    "                inputs = inputs.to(device) \n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # zero the gradient\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # if training phase, allow calculating the gradient, but don't allow otherwise\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # get outputs and predictions\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    loss = criterion(outputs, labels) # get value of loss function with the current weights \n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # keep track of the best weights for the validation dataset \n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best validation Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_68YsD6-gc-o",
    "outputId": "69392d1f-dde6-466a-9282-14dce5000ee4"
   },
   "outputs": [],
   "source": [
    "model = train(model, criterion, optimizer,\n",
    "                         exp_scheduler, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "E6L3Y9dWy4dT",
    "outputId": "63d11d15-9f6d-4c41-9cf4-19a752b73141"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloaders['Test']:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the {} test images: {:.3f}%'.format(dataset_sizes['Test'], \n",
    "                                                                      100 * correct / dataset_sizes['Test']))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNpHaoiCFr2DU0RevXuFXK/",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "13uSexMkWlAYDQeoRg73UUyqPRm0RIf5G",
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2d6ade54451f4a2687da3bdc88e4a863": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "304788cedc904dec887ad1df4014925f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c3657cb204de4850b6c3bde07cd355ed",
       "IPY_MODEL_3ca860ee18a34b11844d9dcaed4c44cf"
      ],
      "layout": "IPY_MODEL_48fe9858dba94bcf8ebda5b0980ab3d5"
     }
    },
    "3ca860ee18a34b11844d9dcaed4c44cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8bc11a88008f42c9a0b3e073b7bfcdd8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c951a746541e411abce3ef98edc0a273",
      "value": " 507M/507M [00:07&lt;00:00, 74.1MB/s]"
     }
    },
    "48fe9858dba94bcf8ebda5b0980ab3d5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bc11a88008f42c9a0b3e073b7bfcdd8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b41d8b7d46404ddb92c246fd040ba9ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3657cb204de4850b6c3bde07cd355ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b41d8b7d46404ddb92c246fd040ba9ff",
      "max": 531456000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2d6ade54451f4a2687da3bdc88e4a863",
      "value": 531456000
     }
    },
    "c951a746541e411abce3ef98edc0a273": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
