{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Copy of home.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBqmcOEPsNWw",
        "colab_type": "text"
      },
      "source": [
        "# HOMEWORK 01\n",
        "\n",
        "## Exercise 1\n",
        "\n",
        "If you consider the definition of the mean as $E[Y] = \\sum_{i = 1}^{n} \\left ( i \\cdot p(i \\right ))$ for a given r.v., than it turns out that:\n",
        "\n",
        "$\\sum_{j = 1}^{N} \\left ( j \\cdot P \\left (Y = j \\right ) \\right ) = \\frac{1}{N} \\cdot \\sum_{j = 1}^{N} \\left ( j \\right ) =\n",
        "\\frac{1}{N} \\cdot \\frac{N \\cdot \\left ( N + 1 \\right )}{2} = \\frac{N + 1}{2}$\n",
        "\n",
        "\n",
        "## Exercise 2\n",
        "\n",
        "If you consider the defintion of mean for the continuous r.v. X as $E[X] = \\int_{-\\infty}^{+\\infty} x \\cdot p(x) \\space dx$, than, the mean for a normal distribution $N(\\mu, \\sigma^2)$ is defined in the following way:\n",
        "\n",
        "$\n",
        "E[X] = \n",
        "\\int_{- \\infty}^{+ \\infty} x \\cdot \\frac{1}{\\sqrt{2 \\cdot \\pi \\cdot \\sigma^2}} \\cdot e^{- \\frac{\\left ( x - \\mu \\right )^2}{\\sigma^2}} \\space dx = \n",
        "$\n",
        "\n",
        "$\n",
        "\\frac{1}{\\sqrt{2 \\cdot \\pi \\cdot \\sigma^2}} \\cdot\\int_{- \\infty}^{+ \\infty} \\left ( x - \\mu + \\mu \\right ) \\cdot e^{- \\frac{\\left ( x - \\mu \\right )^2}{\\sigma^2}} \\space dx =\n",
        "$\n",
        "\n",
        "$\n",
        "\\frac{1}{\\sqrt{2 \\cdot \\pi \\cdot \\sigma^2}} \\cdot \\left [ \n",
        "\\int_{- \\infty}^{+ \\infty} \\left ( x - \\mu \\right ) \\cdot e^{- \\frac{\\left ( x - \\mu \\right )^2}{\\sigma^2}} \\space dx +\n",
        "\\mu \\cdot \\int_{- \\infty}^{+ \\infty} e^{- \\frac{\\left ( x - \\mu \\right )^2}{\\sigma^2}} \\space dx \\right ] =\n",
        "$\n",
        "\n",
        "$\n",
        "\\frac{1}{\\sqrt{2 \\cdot \\pi \\cdot \\sigma^2}} \\cdot \\left [ \n",
        "- 2 \\cdot \\sigma^2 \\cdot \\int_{- \\infty}^{+ \\infty} \\frac{\\left ( x - \\mu \\right )}{\\sigma^2} \\cdot e^{- \\frac{\\left ( x - \\mu \\right )^2}{\\sigma^2}} \\space dx + \\mu \\cdot \\int_{- \\infty}^{+ \\infty} e^{- \\frac{\\left ( x - \\mu \\right )^2}{\\sigma^2}} \\space dx \\right ] = \n",
        "$\n",
        "\n",
        "$\n",
        "\\frac{- 2 \\cdot \\sigma^2}{\\sqrt{2 \\cdot \\pi \\cdot \\sigma^2}} \\cdot \n",
        "\\left [ e^{- \\frac{\\left ( x - \\mu \\right )^2}{\\sigma^2}} \\right ]_{-\\infty}^{+ \\infty} + \\mu \\cdot \\frac{1}{\\sqrt{2 \\cdot \\pi \\cdot \\sigma^2}} \\cdot \\int_{- \\infty}^{+ \\infty} e^{- \\frac{\\left ( x - \\mu \\right )^2}{\\sigma^2}} \\space dx = \n",
        "$\n",
        "\n",
        "\n",
        "$\n",
        "\\frac{- 2 \\cdot \\sigma^2}{\\sqrt{2 \\cdot \\pi \\cdot \\sigma^2}} \\cdot \n",
        "0 + \\mu \\cdot 1 = \\mu\n",
        "$\n",
        "\n",
        "Or, if you consider the Standard Normal Distribution $N \\left (0, 1 \\right )$, and you define the r.v. X as a function of $Y~N\\left ( 0, 1 \\right )$, i.e. $X = \\sigma \\cdot Y + \\mu$ where $\\mu$ and $\\sigma$ are constant; you can easily compute the mean of X by using the mean properties:\n",
        "\n",
        "$\n",
        "E \\left [ X \\right ] = \\left [ \\sigma \\cdot Y + \\mu \\right ] = \\sigma \\cdot \\left [ Y \\right ] + \\mu = \\sigma \\cdot 0 + \\mu = \\mu\n",
        "$.\n",
        "\n",
        "# Exercise 3\n",
        "\n",
        "Two random variables are independents iff $P \\left ( X, Y \\right ) = P \\left ( X \\right ) \\cdot \\left ( Y \\right )$. So, first of all, you have to compute the marginal distributions and than check if their product is equal to the join distribution, in that case the two r.v. are independets:\n",
        "\n",
        "$\n",
        "P \\left ( X \\right ) = \\sum_{Y} \\left ( \\frac{1}{30} \\cdot \\left ( x + y \\right ) \\right ) = \\frac{x + 2}{10}, \\space P \\left ( Y \\right ) = \\sum_{X} \\left ( \\frac{1}{30} \\cdot \\left ( x + y \\right ) \\right ) = \\frac{2 \\cdot y + 1}{30}\n",
        "$\n",
        "\n",
        "In the end you check if the definition is verified:\n",
        "\n",
        "$P \\left ( X \\right ) \\cdot \\left ( Y \\right ) = \\frac{2 \\cdot x \\cdot y + x + 4 \\cdot y + 2}{40} \\neq P \\left ( X, Y \\right )$\n",
        "\n",
        "The random variables are not independents.\n",
        "\n",
        "# Exercise 4\n",
        "\n",
        "Consider the joint constrain $x + y < 1$ and re-write it as $x < 1 - y$, than you can compute the marginal distribution of the Y r.v. as follows:\n",
        "\n",
        "$\n",
        "P \\left ( Y \\right ) = \\int_{0}^{1 - y} 24 \\cdot x \\cdot y \\space dx = 24 \\cdot y \\cdot \\left [ \\frac{x^2}{2} \\right ]_{0}^{1 - y} = 12 \\cdot y \\cdot \\left ( 1 - y \\right )^2\n",
        "$\n",
        "\n",
        "\n",
        "If the r.v. Y assumes the value $\\frac{1}{2}$, than the conditional density of X given Y is:\n",
        "\n",
        "$\n",
        "P \\left ( X | Y = \\frac{1}{2} \\right ) = \\frac{P(X, Y = \\frac{1}{2})}{P(Y = \\frac{1}{2})} = \\frac{24 \\cdot x \\cdot \\frac{1}{2}}{ \\frac{3}{2}} = 8 \\cdot x; \\space 0 < x < \\frac{1}{2}\n",
        "$ \n",
        "\n",
        "# Exercise 5\n",
        "\n",
        "From the join distribution you are able to obtain the marginal distributions of the r.v. implying on the join as follows:\n",
        "$\n",
        "P \\left ( X \\right ) = \\int_{Y} p(x, y) \\space dx\n",
        "$\n",
        "where X and Y are the r.v.. So, by considering the following assumptions:\n",
        "* $\n",
        "C = \\frac{\\gamma \\left ( \\alpha_{1} + \\alpha_{2} + \\alpha_{3} \\right )}{\\gamma \\left ( \\alpha_{1} \\right ) \\cdot \\gamma \\left ( \\alpha_{2} \\right ) \\cdot \\gamma \\left ( \\alpha_{3} \\right )}\n",
        "$\n",
        "\n",
        "* $B_{x} \\left ( \\alpha, \\beta \\right ) = \\frac{\\gamma \\left ( \\alpha \\right ) \\cdot \\gamma \\left ( \\beta \\right )}{\\gamma \\left ( \\alpha + \\beta \\right )} = \\int_{0}^{1} x^{\\alpha - 1} \\cdot \\left ( 1 - x \\right )^{\\beta - 1} \\space dx$\n",
        "\n",
        "You can compute the marginal distribution for Y.\n",
        "\n",
        "$\n",
        "P \\left ( Y \\right ) = \\int_{0}^{1 - y} C \\cdot x^{\\alpha_{1} - 1} \\cdot y^{\\alpha_{2} - 1} \\cdot \\left ( 1 - x -y \\right)^{\\alpha_{3} - 1} \\space dx =\n",
        "$\n",
        "\n",
        "$\n",
        "C \\cdot x^{\\alpha_{1} - 1} \\cdot \\int_{0}^{1 - y} y^{\\alpha_{2} - 1} \\cdot \\left ( 1 - x \\right )^{\\alpha_{3} - 1} \\cdot \\left (1 - \\frac{y}{1 - x} \\right )^{\\alpha_{3} - 1} \\space dx =\n",
        "$\n",
        "\n",
        "$\n",
        "C \\cdot x^{\\alpha_{1} - 1} \\cdot \\int_{0}^{1 - y} \\left ( 1 - x \\right )^{\\alpha_{2} - 1} \\cdot \\left ( \\frac{y}{1 -x} \\right )^{\\alpha_{2} - 1} \\cdot \\left ( 1 - x \\right )^{\\alpha_{3} - 1} \\cdot \\left (1 - \\frac{y}{1 - x} \\right )^{\\alpha_{3} - 1} \\space dx =\n",
        "$\n",
        "\n",
        "$\n",
        "C \\cdot x^{\\alpha_{1} - 1} \\cdot \\left ( 1 - x \\right )^{\\alpha_{2} + \\alpha_{3} - 2} \\cdot \\int_{0}^{1 - y} \\left ( \\frac{y}{1 -x} \\right )^{\\alpha_{2} - 1} \\cdot \\left (1 - \\frac{y}{1 - x} \\right )^{\\alpha_{3} - 1} \\space dx =\n",
        "$\n",
        "\n",
        "$\n",
        "C \\cdot x^{\\alpha_{1} - 1} \\cdot \\left ( 1 - x \\right )^{\\alpha_{2} + \\alpha_{3} - 2} \\cdot \\int_{0}^{1} t^{\\alpha_{2} - 1} \\cdot \\left (1 - t \\right )^{\\alpha_{3} - 1} \\cdot \\left ( 1 - x \\right ) \\space dt =\n",
        "$\n",
        "\n",
        "$\n",
        "C \\cdot x^{\\alpha_{1} - 1} \\cdot \\left ( 1 - x \\right )^{\\alpha_{2} + \\alpha_{3} - 1} \\cdot B \\left ( \\alpha_{2}, \\alpha_{3} \\right ) =\n",
        "$\n",
        "\n",
        "$\n",
        "\\frac{\\gamma \\left ( \\alpha_{1} + \\alpha_{2} + \\alpha_{3} \\right )}{\\gamma \\left ( \\alpha_{1} \\right ) \\cdot \\gamma \\left ( \\alpha_{2} \\right ) \\cdot \\gamma \\left ( \\alpha_{3} \\right )} \\cdot \\frac{\\gamma \\left ( \\alpha_{2} \\right ) \\cdot \\gamma \\left ( \\alpha_{3} \\right )}{\\gamma \\left ( \\alpha_{2} + \\alpha_{3} \\right )} \\cdot x^{\\alpha_{1} - 1} \\cdot \\left ( 1 - x \\right )^{\\alpha_{2} + \\alpha_{3} - 1} =\n",
        "$\n",
        "\n",
        "$\n",
        "\\frac{x^{\\alpha_{1} - 1} \\cdot \\left ( 1 - x \\right )^{\\alpha_{2} + \\alpha_{3} - 1}}{B \\left ( \\alpha_{1}, \\alpha_{2} + \\alpha_{3} \\right )} \\space $~$ \\space B \\left ( \\alpha_{1}, \\alpha_{2} + \\alpha_{3} \\right )\n",
        "$"
      ]
    }
  ]
}
